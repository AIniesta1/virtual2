{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   User ID          400 non-null    int64 \n",
      " 1   Gender           400 non-null    object\n",
      " 2   Age              400 non-null    int64 \n",
      " 3   EstimatedSalary  400 non-null    int64 \n",
      " 4   Purchased        400 non-null    int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 15.8+ KB\n",
      "None\n",
      "            User ID         Age  EstimatedSalary   Purchased\n",
      "count  4.000000e+02  400.000000       400.000000  400.000000\n",
      "mean   1.569154e+07   37.655000     69742.500000    0.357500\n",
      "std    7.165832e+04   10.482877     34096.960282    0.479864\n",
      "min    1.556669e+07   18.000000     15000.000000    0.000000\n",
      "25%    1.562676e+07   29.750000     43000.000000    0.000000\n",
      "50%    1.569434e+07   37.000000     70000.000000    0.000000\n",
      "75%    1.575036e+07   46.000000     88000.000000    1.000000\n",
      "max    1.581524e+07   60.000000    150000.000000    1.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype\n",
      "---  ------           --------------  -----\n",
      " 0   Gender           400 non-null    int64\n",
      " 1   Age              400 non-null    int64\n",
      " 2   EstimatedSalary  400 non-null    int64\n",
      " 3   Purchased        400 non-null    int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 12.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"logistic regression dataset-Social_Network_Ads.csv\")\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "df.drop(columns=[\"User ID\"], inplace=True)\n",
    "\n",
    "df[\"Gender\"] = df[\"Gender\"].apply(lambda x: 1 if x == \"Male\" else 0)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selección de variables\n",
    "X = df.drop([\"Purchased\"], axis=1)\n",
    "y = df[\"Purchased\"]\n",
    "\n",
    "#Preprocesamiento\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "#División de datos \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados con Sobremuestreo Aleatorio:\n",
      "Accuracy: 88.75%\n",
      "Precision: 82.76%\n",
      "Recall: 85.71%\n",
      "F1-Score: 84.21%\n",
      "AUC-ROC: 97.05%\n",
      "\n",
      "Resultados con SMOTE:\n",
      "Accuracy: 88.75%\n",
      "Precision: 82.76%\n",
      "Recall: 85.71%\n",
      "F1-Score: 84.21%\n",
      "AUC-ROC: 97.12%\n",
      "\n",
      "Resultados con Submuestreo Aleatorio:\n",
      "Accuracy: 87.50%\n",
      "Precision: 80.00%\n",
      "Recall: 85.71%\n",
      "F1-Score: 82.76%\n",
      "AUC-ROC: 97.12%\n",
      "\n",
      "Resultados con NearMiss:\n",
      "Accuracy: 88.75%\n",
      "Precision: 91.30%\n",
      "Recall: 75.00%\n",
      "F1-Score: 82.35%\n",
      "AUC-ROC: 96.77%\n",
      "\n",
      "El mejor método de balanceo es: SMOTE con F1-Score: 84.21% y AUC-ROC: 97.12%\n",
      "\n",
      "Resultados con ajuste manual de hiperparámetros:\n",
      "Accuracy: 88.75%\n",
      "Precision: 82.76%\n",
      "Recall: 85.71%\n",
      "F1-Score: 84.21%\n",
      "AUC-ROC: 97.12%\n",
      "\n",
      "Resultados con ajuste automático de hiperparámetros:\n",
      "Mejores parámetros: {'C': 1, 'solver': 'liblinear'}\n",
      "Mejor Accuracy en validación cruzada: 84.88%\n",
      "Accuracy: 88.75%\n",
      "Precision: 82.76%\n",
      "Recall: 85.71%\n",
      "F1-Score: 84.21%\n",
      "AUC-ROC: 97.25%\n",
      "         Real  Predicción\n",
      "0  No clase y  No clase y\n",
      "1     clase y     clase y\n",
      "2  No clase y  No clase y\n",
      "3     clase y     clase y\n",
      "4  No clase y  No clase y\n",
      "5  No clase y  No clase y\n",
      "6     clase y     clase y\n",
      "7  No clase y  No clase y\n",
      "8  No clase y     clase y\n",
      "9  No clase y     clase y\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# MÉTODOS DE BALANCEO DE CLASES\n",
    "# --------------------\n",
    "# 1. Sobremuestreo aleatorio\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 3. Submuestreo aleatorio\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# 4. NearMiss (submuestreo basado en distancia)\n",
    "nearmiss = NearMiss()\n",
    "X_train_nm, y_train_nm = nearmiss.fit_resample(X_train, y_train)\n",
    "\n",
    "# --------------------\n",
    "# EVALUACIÓN DE MÉTODOS DE BALANCEO\n",
    "# --------------------\n",
    "resultados_balanceo = {}\n",
    "\n",
    "def evaluar_balanceo(X_train_resampled, y_train_resampled, metodo):\n",
    "    model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred) * 100\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1]) * 100\n",
    "    resultados_balanceo[metodo] = (f1, auc)\n",
    "    print(f\"\\nResultados con {metodo}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"F1-Score: {f1:.2f}%\")\n",
    "    print(f\"AUC-ROC: {auc:.2f}%\")\n",
    "\n",
    "evaluar_balanceo(X_train_ros, y_train_ros, \"Sobremuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_smote, y_train_smote, \"SMOTE\")\n",
    "evaluar_balanceo(X_train_rus, y_train_rus, \"Submuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_nm, y_train_nm, \"NearMiss\")\n",
    "\n",
    "# Seleccionar el mejor método de balanceo\n",
    "mejor_metodo = max(resultados_balanceo, key=lambda k: resultados_balanceo[k])\n",
    "print(f\"\\nEl mejor método de balanceo es: {mejor_metodo} con F1-Score: {resultados_balanceo[mejor_metodo][0]:.2f}% y AUC-ROC: {resultados_balanceo[mejor_metodo][1]:.2f}%\")\n",
    "\n",
    "# Obtener los datos balanceados del mejor método encontrado\n",
    "if mejor_metodo == \"Sobremuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_ros, y_train_ros\n",
    "elif mejor_metodo == \"SMOTE\":\n",
    "    X_train_resampled, y_train_resampled = X_train_smote, y_train_smote\n",
    "elif mejor_metodo == \"Submuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_rus, y_train_rus\n",
    "elif mejor_metodo == \"NearMiss\":\n",
    "    X_train_resampled, y_train_resampled = X_train_nm, y_train_nm\n",
    "\n",
    "# --------------------\n",
    "# MÉTODO 1: Ajuste manual de hiperparámetros\n",
    "# --------------------\n",
    "manual_model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)  # Ejemplo de hiperparámetros ajustados manualmente\n",
    "manual_model.fit(X_train_resampled, y_train_resampled)  # Entrenar modelo\n",
    "\n",
    "# Predicciones\n",
    "y_pred_manual = manual_model.predict(X_test)\n",
    "\n",
    "# Evaluación del modelo ajustado manualmente\n",
    "print(\"\\nResultados con ajuste manual de hiperparámetros:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, manual_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "# --------------------\n",
    "# MÉTODO 2: Ajuste automático con GridSearchCV\n",
    "# --------------------\n",
    "parametros = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],  # Diferentes valores de regularización\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"]  # Diferentes algoritmos de optimización\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=500), parametros, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)  # Entrenar búsqueda de hiperparámetros\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicciones del mejor modelo\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluación del mejor modelo\n",
    "print(\"\\nResultados con ajuste automático de hiperparámetros:\")\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor Accuracy en validación cruzada: {grid_search.best_score_ * 100:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# ENTRENAMIENTO FINAL Y EVALUACIÓN\n",
    "# --------------------\n",
    "\n",
    "# Entrenar el mejor modelo con los datos balanceados\n",
    "best_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Realizar predicciones finales con el mejor modelo y el mejor balanceo\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "resultados = pd.DataFrame({\n",
    "    \"Real\": y_test.values,\n",
    "    \"Predicción\": y_pred_final\n",
    "})\n",
    "\n",
    "# Mapear valores 0 y 1 a etiquetas comprensibles\n",
    "resultados[\"Real\"] = resultados[\"Real\"].map({0: \"No clase y\", 1: \"clase y\"})\n",
    "resultados[\"Predicción\"] = resultados[\"Predicción\"].map({0: \"No clase y\", 1: \"clase y\"})\n",
    "\n",
    "# Mostrar las primeras filas de la tabla\n",
    "print(resultados.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  target                   569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df[\"target\"] = data.target \n",
    "df.info()\n",
    "print(df[\"target\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selección de variables\n",
    "X = df.drop([\"target\"], axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "#Preprocesamiento\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "#División de datos \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados con Sobremuestreo Aleatorio:\n",
      "Accuracy: 98.25%\n",
      "Precision: 98.59%\n",
      "Recall: 98.59%\n",
      "F1-Score: 98.59%\n",
      "AUC-ROC: 99.80%\n",
      "\n",
      "Resultados con SMOTE:\n",
      "Accuracy: 98.25%\n",
      "Precision: 98.59%\n",
      "Recall: 98.59%\n",
      "F1-Score: 98.59%\n",
      "AUC-ROC: 99.84%\n",
      "\n",
      "Resultados con Submuestreo Aleatorio:\n",
      "Accuracy: 97.37%\n",
      "Precision: 98.57%\n",
      "Recall: 97.18%\n",
      "F1-Score: 97.87%\n",
      "AUC-ROC: 99.84%\n",
      "\n",
      "Resultados con NearMiss:\n",
      "Accuracy: 96.49%\n",
      "Precision: 97.18%\n",
      "Recall: 97.18%\n",
      "F1-Score: 97.18%\n",
      "AUC-ROC: 99.80%\n",
      "\n",
      "El mejor método de balanceo es: SMOTE con F1-Score: 98.59% y AUC-ROC: 99.84%\n",
      "\n",
      "Resultados con ajuste manual de hiperparámetros:\n",
      "Accuracy: 98.25%\n",
      "Precision: 98.59%\n",
      "Recall: 98.59%\n",
      "F1-Score: 98.59%\n",
      "AUC-ROC: 99.84%\n",
      "\n",
      "Resultados con ajuste automático de hiperparámetros:\n",
      "Mejores parámetros: {'C': 0.1, 'solver': 'lbfgs'}\n",
      "Mejor Accuracy en validación cruzada: 98.08%\n",
      "Accuracy: 98.25%\n",
      "Precision: 98.59%\n",
      "Recall: 98.59%\n",
      "F1-Score: 98.59%\n",
      "AUC-ROC: 99.84%\n",
      "         Real  Predicción\n",
      "0     clase y     clase y\n",
      "1  No clase y  No clase y\n",
      "2  No clase y  No clase y\n",
      "3     clase y     clase y\n",
      "4     clase y     clase y\n",
      "5  No clase y  No clase y\n",
      "6  No clase y  No clase y\n",
      "7  No clase y  No clase y\n",
      "8     clase y     clase y\n",
      "9     clase y     clase y\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# MÉTODOS DE BALANCEO DE CLASES\n",
    "# --------------------\n",
    "# 1. Sobremuestreo aleatorio\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 3. Submuestreo aleatorio\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# 4. NearMiss (submuestreo basado en distancia)\n",
    "nearmiss = NearMiss()\n",
    "X_train_nm, y_train_nm = nearmiss.fit_resample(X_train, y_train)\n",
    "\n",
    "# --------------------\n",
    "# EVALUACIÓN DE MÉTODOS DE BALANCEO\n",
    "# --------------------\n",
    "resultados_balanceo = {}\n",
    "\n",
    "def evaluar_balanceo(X_train_resampled, y_train_resampled, metodo):\n",
    "    model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred) * 100\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1]) * 100\n",
    "    resultados_balanceo[metodo] = (f1, auc)\n",
    "    print(f\"\\nResultados con {metodo}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"F1-Score: {f1:.2f}%\")\n",
    "    print(f\"AUC-ROC: {auc:.2f}%\")\n",
    "\n",
    "evaluar_balanceo(X_train_ros, y_train_ros, \"Sobremuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_smote, y_train_smote, \"SMOTE\")\n",
    "evaluar_balanceo(X_train_rus, y_train_rus, \"Submuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_nm, y_train_nm, \"NearMiss\")\n",
    "\n",
    "# Seleccionar el mejor método de balanceo\n",
    "mejor_metodo = max(resultados_balanceo, key=lambda k: resultados_balanceo[k])\n",
    "print(f\"\\nEl mejor método de balanceo es: {mejor_metodo} con F1-Score: {resultados_balanceo[mejor_metodo][0]:.2f}% y AUC-ROC: {resultados_balanceo[mejor_metodo][1]:.2f}%\")\n",
    "\n",
    "# Obtener los datos balanceados del mejor método encontrado\n",
    "if mejor_metodo == \"Sobremuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_ros, y_train_ros\n",
    "elif mejor_metodo == \"SMOTE\":\n",
    "    X_train_resampled, y_train_resampled = X_train_smote, y_train_smote\n",
    "elif mejor_metodo == \"Submuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_rus, y_train_rus\n",
    "elif mejor_metodo == \"NearMiss\":\n",
    "    X_train_resampled, y_train_resampled = X_train_nm, y_train_nm\n",
    "\n",
    "# --------------------\n",
    "# MÉTODO 1: Ajuste manual de hiperparámetros\n",
    "# --------------------\n",
    "manual_model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)  # Ejemplo de hiperparámetros ajustados manualmente\n",
    "manual_model.fit(X_train_resampled, y_train_resampled)  # Entrenar modelo\n",
    "\n",
    "# Predicciones\n",
    "y_pred_manual = manual_model.predict(X_test)\n",
    "\n",
    "# Evaluación del modelo ajustado manualmente\n",
    "print(\"\\nResultados con ajuste manual de hiperparámetros:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, manual_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "# --------------------\n",
    "# MÉTODO 2: Ajuste automático con GridSearchCV\n",
    "# --------------------\n",
    "parametros = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],  # Diferentes valores de regularización\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"]  # Diferentes algoritmos de optimización\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=500), parametros, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)  # Entrenar búsqueda de hiperparámetros\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicciones del mejor modelo\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluación del mejor modelo\n",
    "print(\"\\nResultados con ajuste automático de hiperparámetros:\")\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor Accuracy en validación cruzada: {grid_search.best_score_ * 100:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# ENTRENAMIENTO FINAL Y EVALUACIÓN\n",
    "# --------------------\n",
    "\n",
    "# Entrenar el mejor modelo con los datos balanceados\n",
    "best_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Realizar predicciones finales con el mejor modelo y el mejor balanceo\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "resultados = pd.DataFrame({\n",
    "    \"Real\": y_test.values,\n",
    "    \"Predicción\": y_pred_final\n",
    "})\n",
    "\n",
    "# Mapear valores 0 y 1 a etiquetas comprensibles\n",
    "resultados[\"Real\"] = resultados[\"Real\"].map({0: \"No clase y\", 1: \"clase y\"})\n",
    "resultados[\"Predicción\"] = resultados[\"Predicción\"].map({0: \"No clase y\", 1: \"clase y\"})\n",
    "\n",
    "# Mostrar las primeras filas de la tabla\n",
    "print(resultados.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 19,  20,  21,  37,  46,  48,  49,  50,  51,  52,\n",
      "       ...\n",
      "       553, 554, 555, 556, 557, 558, 559, 560, 561, 568],\n",
      "      dtype='int64', length=357)\n",
      "mean radius                 13.030000\n",
      "mean texture                18.420000\n",
      "mean perimeter              82.610000\n",
      "mean area                  523.800000\n",
      "mean smoothness              0.089830\n",
      "mean compactness             0.037660\n",
      "mean concavity               0.025620\n",
      "mean concave points          0.029230\n",
      "mean symmetry                0.146700\n",
      "mean fractal dimension       0.058630\n",
      "radius error                 0.183900\n",
      "texture error                2.342000\n",
      "perimeter error              1.170000\n",
      "area error                  14.160000\n",
      "smoothness error             0.004352\n",
      "compactness error            0.004899\n",
      "concavity error              0.013430\n",
      "concave points error         0.011640\n",
      "symmetry error               0.026710\n",
      "fractal dimension error      0.001777\n",
      "worst radius                13.300000\n",
      "worst texture               22.810000\n",
      "worst perimeter             84.460000\n",
      "worst area                 545.900000\n",
      "worst smoothness             0.097010\n",
      "worst compactness            0.046190\n",
      "worst concavity              0.048330\n",
      "worst concave points         0.050130\n",
      "worst symmetry               0.198700\n",
      "worst fractal dimension      0.061690\n",
      "target                       1.000000\n",
      "Name: 37, dtype: float64\n",
      "\n",
      "Ingrese los valores para realizar una predicción:\n",
      "\n",
      "Predicción: Benigno (100.00% de confianza)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lalos\\OneDrive\\Escritorio\\virtual2\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# PRUEBA Y EJECUCIÓN DEL MODELO\n",
    "# --------------------\n",
    "\n",
    "\n",
    "# Buscamos un registro de un paciente con cancer para pasar los mismos datos y probar que el modelo predice correctamente\n",
    "print(df[df[\"target\"] == 1].index) # Seleccionamos la 37\n",
    "print(df.loc[37])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Mapeo de características a nombres en castellano (opcional)\n",
    "nombres_caracteristicas = {\n",
    "    'mean radius': 'Radio promedio',\n",
    "    'mean texture': 'Textura promedio',\n",
    "    'mean perimeter': 'Perímetro promedio',\n",
    "    'mean area': 'Área promedio',\n",
    "    'mean smoothness': 'Suavidad promedio',\n",
    "    'mean compactness': 'Compacidad promedio',\n",
    "    'mean concavity': 'Concavidad promedio',\n",
    "    'mean concave points': 'Puntos cóncavos promedio',\n",
    "    'mean symmetry': 'Simetría promedio',\n",
    "    'mean fractal dimension': 'Dimensión fractal promedio',\n",
    "    'radius error': 'Error de radio',\n",
    "    'texture error': 'Error de textura',\n",
    "    'perimeter error': 'Error de perímetro',\n",
    "    'area error': 'Error de área',\n",
    "    'smoothness error': 'Error de suavidad',\n",
    "    'compactness error': 'Error de compacidad',\n",
    "    'concavity error': 'Error de concavidad',\n",
    "    'concave points error': 'Error de puntos cóncavos',\n",
    "    'symmetry error': 'Error de simetría',\n",
    "    'fractal dimension error': 'Error de dimensión fractal',\n",
    "    'worst radius': 'Radio máximo',\n",
    "    'worst texture': 'Textura máxima',\n",
    "    'worst perimeter': 'Perímetro máximo',\n",
    "    'worst area': 'Área máxima',\n",
    "    'worst smoothness': 'Suavidad máxima',\n",
    "    'worst compactness': 'Compacidad máxima',\n",
    "    'worst concavity': 'Concavidad máxima',\n",
    "    'worst concave points': 'Puntos cóncavos máximos',\n",
    "    'worst symmetry': 'Simetría máxima',\n",
    "    'worst fractal dimension': 'Dimensión fractal máxima'\n",
    "}\n",
    "\n",
    "# Creamos la función para ejecutar el modelo con nuevos datos\n",
    "def solicitar_datos_y_predecir(modelo, feature_names, scaler):\n",
    "    print(\"\\nIngrese los valores para realizar una predicción:\")\n",
    "    valores = []\n",
    "    \n",
    "    for feature in feature_names:\n",
    "        nombre_caracteristica = nombres_caracteristicas.get(feature, feature)  \n",
    "        while True:\n",
    "            try:\n",
    "                valor = float(input(f\"{nombre_caracteristica}: \"))\n",
    "                valores.append(valor)\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"Entrada inválida. Ingrese un número válido.\")\n",
    "    \n",
    "    # Convertir la entrada en un array de numpy y escalarlo con el scaler ya entrenado\n",
    "    datos_nuevos = np.array(valores).reshape(1, -1)\n",
    "    datos_nuevos_escalados = scaler.transform(datos_nuevos)\n",
    "    \n",
    "    # Realizar predicción\n",
    "    prediccion = modelo.predict(datos_nuevos_escalados)[0]\n",
    "    probabilidad = modelo.predict_proba(datos_nuevos_escalados)[0][prediccion] * 100\n",
    "    \n",
    "    # Mostrar resultado\n",
    "    resultado = \"Maligno\" if prediccion == 1 else \"Benigno\"\n",
    "    print(f\"\\nPredicción: {resultado} ({probabilidad:.2f}% de confianza)\\n\")\n",
    "\n",
    "# Llamar a la función con el scaler ya ajustado\n",
    "solicitar_datos_y_predecir(best_model, data.feature_names, scaler)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
