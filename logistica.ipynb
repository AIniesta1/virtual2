{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp_var_rate    41188 non-null  float64\n",
      " 16  cons_price_idx  41188 non-null  float64\n",
      " 17  cons_conf_idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr_employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(10)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "import numpy as np\n",
    "# Cargar datos\n",
    "df = pd.read_csv(\"banking.csv\")\n",
    "\n",
    "#Inspeccionar\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blue-collar' 'technician' 'management' 'services' 'retired' 'admin.'\n",
      " 'housemaid' 'unemployed' 'entrepreneur' 'self-employed' 'unknown'\n",
      " 'student']\n",
      "['married' 'single' 'divorced' 'unknown']\n",
      "['basic.4y' 'unknown' 'university.degree' 'high.school' 'basic.9y'\n",
      " 'professional.course' 'basic.6y' 'illiterate']\n",
      "['unknown' 'no' 'yes']\n",
      "['yes' 'no' 'unknown']\n",
      "['no' 'yes' 'unknown']\n",
      "['cellular' 'telephone']\n",
      "['aug' 'nov' 'jun' 'apr' 'jul' 'may' 'oct' 'mar' 'sep' 'dec']\n",
      "['thu' 'fri' 'tue' 'mon' 'wed']\n",
      "['nonexistent' 'success' 'failure']\n",
      "['Basic' 'unknown' 'university.degree' 'high.school' 'professional.course'\n",
      " 'illiterate']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"job\"].unique()) #get_dummies()\n",
    "print(df[\"marital\"].unique()) #get_dummies()\n",
    "print(df[\"education\"].unique()) #label / get_dummies()\n",
    "print(df[\"default\"].unique()) #get_dummies()\n",
    "print(df[\"housing\"].unique()) #get_dummies()\n",
    "print(df[\"loan\"].unique()) #get_dummies()\n",
    "print(df[\"contact\"].unique()) #get_dummies() o valores binarios\n",
    "print(df[\"month\"].unique()) #get_dummies()\n",
    "print(df[\"day_of_week\"].unique()) #get_dummies()\n",
    "print(df[\"poutcome\"].unique()) #get_dummies()\n",
    "\n",
    "df['education'] = np.where((df['education'] == 'basic.4y') | (df['education'] == 'basic.9y') | (df['education'] == 'basic.6y'), 'Basic', df['education'])\n",
    "print(df[\"education\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=[\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"day_of_week\", \"poutcome\"], drop_first=True)\n",
    "\n",
    "#Selección de variables\n",
    "X = df.drop([\"y\"], axis=1)\n",
    "y = df[\"y\"]\n",
    "\n",
    "#Preprocesamiento\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "#División de datos \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados con Sobremuestreo Aleatorio:\n",
      "Accuracy: 85.64%\n",
      "Precision: 43.76%\n",
      "Recall: 89.29%\n",
      "F1-Score: 58.74%\n",
      "AUC-ROC: 93.52%\n",
      "\n",
      "Resultados con SMOTE:\n",
      "Accuracy: 86.17%\n",
      "Precision: 44.76%\n",
      "Recall: 88.76%\n",
      "F1-Score: 59.51%\n",
      "AUC-ROC: 93.41%\n",
      "\n",
      "Resultados con Submuestreo Aleatorio:\n",
      "Accuracy: 85.43%\n",
      "Precision: 43.40%\n",
      "Recall: 89.61%\n",
      "F1-Score: 58.48%\n",
      "AUC-ROC: 93.39%\n",
      "\n",
      "Resultados con NearMiss:\n",
      "Accuracy: 74.36%\n",
      "Precision: 29.32%\n",
      "Recall: 87.91%\n",
      "F1-Score: 43.98%\n",
      "AUC-ROC: 88.33%\n",
      "\n",
      "El mejor método de balanceo es: SMOTE con F1-Score: 59.51% y AUC-ROC: 93.41%\n",
      "\n",
      "Resultados con ajuste manual de hiperparámetros:\n",
      "Accuracy: 86.17%\n",
      "Precision: 44.76%\n",
      "Recall: 88.76%\n",
      "F1-Score: 59.51%\n",
      "AUC-ROC: 93.41%\n",
      "\n",
      "Resultados con ajuste automático de hiperparámetros:\n",
      "Mejores parámetros: {'C': 10, 'solver': 'lbfgs'}\n",
      "Mejor Accuracy en validación cruzada: 88.52%\n",
      "Accuracy: 86.17%\n",
      "Precision: 44.74%\n",
      "Recall: 88.44%\n",
      "F1-Score: 59.42%\n",
      "AUC-ROC: 93.39%\n",
      "         Real  Predicción\n",
      "0  No clase y  No clase y\n",
      "1     clase y  No clase y\n",
      "2     clase y     clase y\n",
      "3  No clase y  No clase y\n",
      "4  No clase y  No clase y\n",
      "5     clase y  No clase y\n",
      "6  No clase y  No clase y\n",
      "7  No clase y  No clase y\n",
      "8  No clase y  No clase y\n",
      "9  No clase y  No clase y\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# MÉTODOS DE BALANCEO DE CLASES\n",
    "# --------------------\n",
    "# 1. Sobremuestreo aleatorio\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 3. Submuestreo aleatorio\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# 4. NearMiss (submuestreo basado en distancia)\n",
    "nearmiss = NearMiss()\n",
    "X_train_nm, y_train_nm = nearmiss.fit_resample(X_train, y_train)\n",
    "\n",
    "# --------------------\n",
    "# EVALUACIÓN DE MÉTODOS DE BALANCEO\n",
    "# --------------------\n",
    "resultados_balanceo = {}\n",
    "\n",
    "def evaluar_balanceo(X_train_resampled, y_train_resampled, metodo):\n",
    "    model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred) * 100\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1]) * 100\n",
    "    resultados_balanceo[metodo] = (f1, auc)\n",
    "    print(f\"\\nResultados con {metodo}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"F1-Score: {f1:.2f}%\")\n",
    "    print(f\"AUC-ROC: {auc:.2f}%\")\n",
    "\n",
    "evaluar_balanceo(X_train_ros, y_train_ros, \"Sobremuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_smote, y_train_smote, \"SMOTE\")\n",
    "evaluar_balanceo(X_train_rus, y_train_rus, \"Submuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_nm, y_train_nm, \"NearMiss\")\n",
    "\n",
    "# Seleccionar el mejor método de balanceo\n",
    "mejor_metodo = max(resultados_balanceo, key=lambda k: resultados_balanceo[k])\n",
    "print(f\"\\nEl mejor método de balanceo es: {mejor_metodo} con F1-Score: {resultados_balanceo[mejor_metodo][0]:.2f}% y AUC-ROC: {resultados_balanceo[mejor_metodo][1]:.2f}%\")\n",
    "\n",
    "# Obtener los datos balanceados del mejor método encontrado\n",
    "if mejor_metodo == \"Sobremuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_ros, y_train_ros\n",
    "elif mejor_metodo == \"SMOTE\":\n",
    "    X_train_resampled, y_train_resampled = X_train_smote, y_train_smote\n",
    "elif mejor_metodo == \"Submuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_rus, y_train_rus\n",
    "elif mejor_metodo == \"NearMiss\":\n",
    "    X_train_resampled, y_train_resampled = X_train_nm, y_train_nm\n",
    "\n",
    "# --------------------\n",
    "# MÉTODO 1: Ajuste manual de hiperparámetros\n",
    "# --------------------\n",
    "manual_model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)  # Ejemplo de hiperparámetros ajustados manualmente\n",
    "manual_model.fit(X_train_resampled, y_train_resampled)  # Entrenar modelo\n",
    "\n",
    "# Predicciones\n",
    "y_pred_manual = manual_model.predict(X_test)\n",
    "\n",
    "# Evaluación del modelo ajustado manualmente\n",
    "print(\"\\nResultados con ajuste manual de hiperparámetros:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, manual_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "# --------------------\n",
    "# MÉTODO 2: Ajuste automático con GridSearchCV\n",
    "# --------------------\n",
    "parametros = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],  # Diferentes valores de regularización\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"]  # Diferentes algoritmos de optimización\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=500), parametros, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)  # Entrenar búsqueda de hiperparámetros\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicciones del mejor modelo\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluación del mejor modelo\n",
    "print(\"\\nResultados con ajuste automático de hiperparámetros:\")\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor Accuracy en validación cruzada: {grid_search.best_score_ * 100:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# ENTRENAMIENTO FINAL Y EVALUACIÓN\n",
    "# --------------------\n",
    "\n",
    "# Entrenar el mejor modelo con los datos balanceados\n",
    "best_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Realizar predicciones finales con el mejor modelo y el mejor balanceo\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "resultados = pd.DataFrame({\n",
    "    \"Real\": y_test.values,\n",
    "    \"Predicción\": y_pred_final\n",
    "})\n",
    "\n",
    "# Mapear valores 0 y 1 a etiquetas comprensibles\n",
    "resultados[\"Real\"] = resultados[\"Real\"].map({0: \"No clase y\", 1: \"clase y\"})\n",
    "resultados[\"Predicción\"] = resultados[\"Predicción\"].map({0: \"No clase y\", 1: \"clase y\"})\n",
    "\n",
    "# Mostrar las primeras filas de la tabla\n",
    "print(resultados.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
